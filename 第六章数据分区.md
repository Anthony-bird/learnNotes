### 数据分区



### 键－值数据的分区

**分区的目的为了提高可扩展性。**不同的分区可以放在不同的节点上，每个分区可以有多个副本。这样一个数据集就可以分散在不同的节点的磁盘上，查询负载也就随之分散到不同的节点上。

#### 基于关键字区间分区

这种方式为每个分区分配一段连续的关键字或者关键字区间范围（最小和最大值）。

首先，先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。采用这种分区策略的系统有 Bigtable，Bigtable的开源版本HBase，MongoDB（<2.4）等。这种方式的优点在于，支持高效的关键字区间查询。这种方式的缺点在于某些访问模式会导致热点。若关键字是时间戳，则分区对应一个时间范围，例如每天一个分区，此时，当某一天的数据写入时，会集中在同一个分区，会导致该分区写入负载过高。解决方案是修改关键字，在时间戳前面加上一些不一致的字段。

#### 基于关键字哈希值分区

一个好的哈希函数可以处理数据倾斜并且使其均匀分布。例如 MongoDB 采用的 MD5。

这种方式给每个分区一个哈希范围，关键字根据其哈希值的范围划分到不同的分区中。

这种方式可以很好地将关键字均匀分配到多个分区中。分区边界可以是均匀间隔，也可以是伪随机选择（一致性哈希）。

这种方式的缺点在于，丧失了良好的关键字区间查询特性。即使关键字相邻，但是其哈希值可能千差万别，因此相邻的关键字经过哈希之后会划分到不同的分区中。例如，MongoDB 若启用了哈希分片，则区间查询会发送到所有的分区上。

采用这种方式时，通常事先需要创建好足够多（但是数量固定）的分区，让每个节点承担更多分区，当添加或者删除节点时，需要进行分区迁移，也可以支持动态分区。



#### 负载倾斜与系统热点

基于关键字哈希值分区尽管可以降低系统热点，但是并不能完全避免，例如对同一个关键字的大量读写请求最终所有路由都会到同一个分区。目前来说，这种负载倾斜只能够通过应用层降低，例如对热点数据增加扰动值，将一个热点数据分到不同的分区中，但是随之带来的问题就是读操作也需要做相同的操作进行读取，这种手段仅适用于少量热点关键字。



### 分区与二级索引

二级索引带来的挑战是他们不能规整的映射到分区中。有两种方法支持二级索引的分区。



#### 基于文档分区的二级索引（本地索引）

二级索引存储在与关键字相同的分区。每个分区完全独立，各自维护自己的二级索引，只负责自己分区内的文档而不关心其他分区的数据。优点是写入时只需要更新一个分区，缺点是读取二级索引时，往往需要在所有分区上执行 scatter/gather。

#### 基于词条分区的二级索引分区（全局索引）

基于索引的值进行独立的分区。二级索引中的条目可能包含来自关键字的多个分区的记录。二级索引维护所有分区的数据，同时二级索引也和关键词索引一样进行分区。优点是，读取时可以从单个分区读取数据，缺点是写入时需要更新二级索引的多个分区。



### 分区再平衡

分区再平衡：请求和数据从一个节点转移到另外一个节点，这样的一个迁移负载的过程称为再平衡（动态平衡）。分区再平衡需要满足：

- 再平衡后能达到想要的负载平衡效果
- 再平衡发生时，分片应该继续接受读取和写入
- 节点之间只移动必须的数据，减少平衡时间



#### 动态再平衡策略

#### 为何不用取模？

取模方法的问题在于，节点数N发生变化后，会导致很多关键字需要从现有节点迁移到另外的节点。这种频繁迁移的话会大大增大再平衡的成本。

#### 固定数量的分区

数据库创建固定数量的分区，每个节点可以有多个分区，各个节点分区均匀分布。增加节点时，每个节点分配部分分区给新入节点；删除节点时，将删除节点的分区均匀分给其他节点。对于硬件比较强悍的机器也可以分配更多的分区。

#### 动态分区

数据库分区数量不定，初始分区数可能是一个或者一组（这被称为预分裂）。随着数据量的变化，分区数量不停的增大或者缩小，处于动态变化之中。动态分区不仅适用于关键字区间分区，而且适用于基于哈希的分区策略。











